{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977afb19-9599-41e4-8327-daa17a13c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets up basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import astropy.units as u\n",
    "import astropy.cosmology.units as cu\n",
    "\n",
    "# this sets up matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this sets up astropy\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.coordinates import SkyCoord, Angle, match_coordinates_sky, Distance\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "from astropy.table import Table\n",
    "\n",
    "from regions import Regions, CircleSkyRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f6c67e-61e2-4b4f-b4ba-57fdfb81f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, import the file of neighbor data, which is a csv\n",
    "df = pd.read_csv('neighbor_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd235c-1a24-4644-bd68-ab27a7c0892b",
   "metadata": {},
   "source": [
    "First, we deal with the space-based observations from Hollis's catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ebe586-0d7c-4a43-a695-b6bffd315537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f814w', 'f115w', 'f150w', 'f277w', 'f444w', 'f770w']\n",
      "['f814w', 'f115w', 'f150w', 'f277w', 'f444w', 'f770w', 'f606w', 'f090w', 'f200w', 'f356w', 'f410m']\n"
     ]
    }
   ],
   "source": [
    "# this reads in all the COSMOS-Web measurements in different bands\n",
    "f_cweb_cols = [col for col in df.columns if 'f_auto' in col]\n",
    "e_cweb_cols = [col for col in df.columns if 'e_auto' in col]\n",
    "\n",
    "# this saves the names of the COSMOS-Web bands\n",
    "space_band_names = []\n",
    "for header in f_cweb_cols:\n",
    "    name = header[-5:] # this gets the band name, which are the last 5 characters of the column header\n",
    "    space_band_names.append(name)\n",
    "\n",
    "# check how many bands we've had for the first time\n",
    "print(space_band_names)\n",
    "\n",
    "# this reads in all the PRIMER measurements in different bands\n",
    "f_primer_cols = [col for col in df.columns if 'f_primer_auto' in col]\n",
    "e_primer_cols = [col for col in df.columns if 'e_primer_auto' in col]\n",
    "\n",
    "# this saves the names of the PRIMER bands\n",
    "for header in f_primer_cols:\n",
    "    name = header[-5:] # this gets the band name, which are the last 5 characters of the column header\n",
    "    if name not in space_band_names:\n",
    "        space_band_names.append(name)\n",
    "\n",
    "# check how many bands we've had for the second time\n",
    "print(space_band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3caac040-ccbd-4987-8230-9aa4a37d9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we make a simple 5sigma to 3sigma conversion. this is for later usage\n",
    "def convert_3sigma(m_5sig):\n",
    "    m_3sig = m_5sig - np.log10(5) + np.log10(3)\n",
    "    return m_3sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7de98f6-839e-4d4a-b17a-e0369c930231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we make a list of the 3sigma for each space band. the sources are \n",
    "# Weaver et al (2020): arxiv.org/pdf/2110.13923, and Casey et al (2023): iopscience.iop.org/article/10.3847/1538-4357/acc2bc/pdf.\n",
    "# note that for values from Casey et al, they're actually 5sigma and have to be recalculated as 3sigma.\n",
    "space_3sigma_list = [27.8, convert_3sigma(27.13), convert_3sigma(27.35), convert_3sigma(27.99), convert_3sigma(27.83), \n",
    "                     convert_3sigma(25.70), convert_3sigma(27.8), convert_3sigma(27.6), convert_3sigma(28.2), \n",
    "                     convert_3sigma(28.4), convert_3sigma(27.7)] # \n",
    "\n",
    "# now we combine everything into a dictionary so it's easier to sort through later\n",
    "space_3sigma_dict = {space_band_names[i]: space_3sigma_list[i] for i in range(len(space_band_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5b5555-1b88-43e8-9c17-61c877c35897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f814w': 27.8, 'f115w': 26.908151250383643, 'f150w': 27.128151250383645, 'f277w': 27.768151250383642, 'f444w': 27.608151250383642, 'f770w': 25.478151250383643, 'f606w': 27.578151250383645, 'f090w': 27.378151250383645, 'f200w': 27.978151250383643, 'f356w': 28.178151250383642, 'f410m': 27.478151250383643}\n"
     ]
    }
   ],
   "source": [
    "print(space_3sigma_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc709f-006b-44c1-bfe4-b9cf48a8bd52",
   "metadata": {},
   "source": [
    "Now let's do the dreaded for-loop that goes through the data and gets the best fluxes and flux errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1d00bf-b99e-47aa-8a24-2918d9b46bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR THE SPACE-BASED DATA\n",
    "\n",
    "fluxes = []\n",
    "errors = []\n",
    "\n",
    "for name in space_band_names:    \n",
    "    ### first, read in the headers of the bands that are available in both COSMOS-Web and PRIMER\n",
    "    cweb_flux_header = [header for header in f_cweb_cols if name in header]\n",
    "    cweb_err_header = [header for header in e_cweb_cols if name in header]\n",
    "    primer_flux_header = [header for header in f_primer_cols if name in header]\n",
    "    primer_err_header = [header for header in e_primer_cols if name in header]\n",
    "\n",
    "    ### next, load in the 3sigmas from our dictionary. remember that \n",
    "    ### our 3sigma values, which are given in magnitudes, need to be converted into uJy.\n",
    "    three_sigma = (10**((23.9-space_3sigma_dict[name])/2.5))\n",
    "    \n",
    "    ### next, check to see if the bands with these headers actually exist for BOTH COSMOS-Web AND PRIMER\n",
    "    if len(cweb_flux_header) != 0 and len(primer_flux_header) != 0:\n",
    "        # next, check to see how much of the data under these headers is actually NaN.\n",
    "        # if they're NaN, set them to -99.0, so CIGALE will ignore them later on.\n",
    "        cweb_flux = df[cweb_flux_header[0]].replace(np.nan, -99.0)\n",
    "        cweb_err = df[cweb_err_header[0]].replace(np.nan, -99.0)\n",
    "        primer_flux = df[primer_flux_header[0]].replace(np.nan, -99.0)\n",
    "        primer_err = df[primer_err_header[0]].replace(np.nan, -99.0)\n",
    "\n",
    "        # next, check for values that are less than zero. these values will be set to -99.0 as well.\n",
    "        cweb_flux[cweb_flux <= 0] = 0 \n",
    "        cweb_err[cweb_err <= 0] = three_sigma\n",
    "        primer_flux[primer_flux <= 0] = 0\n",
    "        primer_err[primer_err <= 0] = three_sigma\n",
    "        \n",
    "        # then we calculate and compare the signal-to-noise ratio (SNR), \n",
    "        # then take the one (PRIMER vs COSMOS-Web) with the greater SNR.\n",
    "        cweb_snr = cweb_flux / cweb_err\n",
    "        primer_snr = primer_flux / primer_err\n",
    "\n",
    "        # create an empty array to save the flux and flux error with better SNR\n",
    "        better_flux = np.zeros(np.size(cweb_snr))\n",
    "        better_err = np.zeros(np.size(cweb_snr))\n",
    "        better_snr = np.zeros(np.size(cweb_snr))\n",
    "        for i in range(np.size(cweb_snr)):\n",
    "            if primer_snr[i] > cweb_snr[i]: # if PRIMER's SNR is greater than CWeb's, then keep PRIMER's flux, error & SNR\n",
    "                better_flux[i] = primer_flux[i]\n",
    "                better_err[i] = primer_err[i]\n",
    "                better_snr[i] = primer_snr[i]\n",
    "            else: # else if PRIMER's SNR is smaller than CWeb's, then keep CWeb's flux, error & SNR\n",
    "                better_flux[i] = cweb_flux[i]\n",
    "                better_err[i] = cweb_err[i]\n",
    "                better_snr[i] = cweb_snr[i]\n",
    "\n",
    "    ### now, check the cases where there is CWeb data but NO PRIMER data\n",
    "    elif len(cweb_flux_header) != 0:\n",
    "        cweb_flux = df[cweb_flux_header[0]].replace(np.nan, -99.0)\n",
    "        cweb_err = df[cweb_err_header[0]].replace(np.nan, -99.0)\n",
    "\n",
    "        # then we calculate the SNR\n",
    "        better_flux = cweb_flux\n",
    "        better_err = cweb_err\n",
    "        better_snr = cweb_flux / cweb_err\n",
    "\n",
    "    ### finally, check the cases where there is PRIMER data but NO CWeb data\n",
    "    else:\n",
    "        primer_flux = df[primer_flux_header[0]].replace(np.nan, -99.0)\n",
    "        primer_err = df[primer_err_header[0]].replace(np.nan, -99.0)\n",
    "\n",
    "        # then we calculate the SNR\n",
    "        better_flux = primer_flux\n",
    "        better_err = primer_err\n",
    "        better_snr = primer_flux / primer_err\n",
    "\n",
    "    ### NOW, after gathering all this, we check for the final time to see if the SNR is less than or equal to 3.\n",
    "    ### if yes, we'll set the error to be equal to the flux, and the flux to be equal to 0. we have to do this\n",
    "    ### because CIGALE likes to make weird estimational violations when it comes to large upper limits.\n",
    "    for i in range(np.size(better_snr)):\n",
    "        SNR = better_snr[i]\n",
    "        if SNR <= 3:\n",
    "            better_err[i] = three_sigma\n",
    "            better_flux[i] = 0\n",
    "\n",
    "    ### finally, we convert all the fluxes and errors \n",
    "    ### from Î¼Jy (the unit used in Hollis's table) to mJy (the unit that CIGALE takes)\n",
    "    better_flux = better_flux / 1e3\n",
    "    better_err = better_err / 1e3\n",
    "\n",
    "    ### at last, we can escape this hellscape of a for-loop.\n",
    "    ### save the fluxes and errors into a list so we can read later.\n",
    "    fluxes.append(better_flux)\n",
    "    errors.append(better_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e6aff-1d76-4189-a57c-cf50990219c1",
   "metadata": {},
   "source": [
    "After this trial and tribulation of a for-loop, let's do a sanity check!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7f839-8385-4b4d-b4fb-33da90cd1763",
   "metadata": {},
   "source": [
    "Then, at last, we deal with the ground-based observations from Marko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77feca8-74f4-4995-9e51-04471b75b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CFHT-u', 'HSC-g', 'HSC-r', 'HSC-i', 'HSC-z', 'HSC-y', 'UVISTA-Y', 'UVISTA-J', 'UVISTA-H', 'UVISTA-Ks', 'SC-IB427', 'SC-IB505', 'SC-IB574', 'SC-IB709', 'SC-IB827', 'SC-NB711', 'SC-NB816', 'IRAC-ch1', 'IRAC-ch2', 'IRAC-ch3']\n"
     ]
    }
   ],
   "source": [
    "# this reads in all the ground-based data from Marko\n",
    "f_ground_cols = [col for col in df.columns if col.startswith('FLUX_MODEL')]\n",
    "e_ground_cols = [col for col in df.columns if col.startswith('FLUX_ERR_MODEL')]\n",
    "\n",
    "# this adds all the bands in Marko's ground-based catalog\n",
    "ground_band_names = []\n",
    "for header in f_ground_cols:\n",
    "    name = header[11:] # this gets the band name\n",
    "    # because CIGALE doesn't have all the bands of each observatory,\n",
    "    # we'll have to do some exclusion\n",
    "    if name.startswith('CFHT'):\n",
    "        ground_band_names.append(name)\n",
    "    elif name.startswith('HSC') and len(name[7:]) < 2:\n",
    "        ground_band_names.append(name)\n",
    "    elif name.startswith('UVISTA') and len(name[7:]) < 3:\n",
    "        ground_band_names.append(name)\n",
    "    elif name.startswith('SC-IB') or name.startswith('SC-NB'):\n",
    "        ground_band_names.append(name)\n",
    "    elif name.startswith('IRAC') and int(name[-1]) < 4: # exclude IRAC-ch4 because there's no error column for this\n",
    "        ground_band_names.append(name)\n",
    "\n",
    "# check to see if we get the right bands\n",
    "print(ground_band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf3e063-5973-4107-91aa-5de6f81b6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we make a list of the 3sigma for each ground band. the source is Weaver et al (2020): arxiv.org/pdf/2110.13923.\n",
    "ground_3sigma_list = [27.2, 27.5, 27.2, 27.0, 26.6, 25.9, 26.1, 25.9, 25.5, 25.2, \n",
    "                    25.6, 25.6, 25.3, 25.4, 25.1, 24.9, 25.1, 25.7, 25.6, 22.6]\n",
    "\n",
    "# now we combine everything into a dictionary so it's easier to sort through later\n",
    "ground_3sigma_dict = {ground_band_names[i]: ground_3sigma_list[i] for i in range(len(ground_band_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8adcd2e6-8124-4187-a470-a154b78a7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR THE GROUND-BASED DATA\n",
    "\n",
    "for name in ground_band_names:\n",
    "    ### first, read in the headers of the bands\n",
    "    flux_header = [header for header in f_ground_cols if name in header]\n",
    "    err_header = [header for header in e_ground_cols if name in header]\n",
    "\n",
    "    ### next, we recalculate the data. there's this issue where, according to Arianna, the software used\n",
    "    ### to measure Marko's fluxes has a bug where it claims to measure sources below the limit, \n",
    "    ### which is not possible. therefore, we'll pick the flux values that are below 3sigma survey limits\n",
    "    ### and then set that to zero, and then set the corresponding flux errors to 3sigma.\n",
    "\n",
    "    # first, load in the 3sigmas from our dictionary. remember that our 3sigma values, which came from\n",
    "    # the COSMOS2020 paper, need to be converted from magnitudes into uJy.\n",
    "    three_sigma = (10**((23.9-ground_3sigma_dict[name])/2.5))\n",
    "\n",
    "    # next, reset the flux values below 3sigma to zero, and reset the errors there to 3sigma.\n",
    "    flux = df[flux_header[0]]\n",
    "    err = df[err_header[0]]\n",
    "    flux[flux < three_sigma] = 0\n",
    "    err[flux < three_sigma] = three_sigma\n",
    "\n",
    "    # finally, check to see how much of the data under these headers is actually NaN.\n",
    "    # if they're NaN, set them to -99.0, so CIGALE will ignore them later on.\n",
    "    flux = flux.replace(np.nan, -99.0)\n",
    "    err = err.replace(np.nan, -99.0)\n",
    "\n",
    "    ### save the fluxes and errors into a list so we can read later.\n",
    "    fluxes.append(flux)\n",
    "    errors.append(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6be06-55d8-49fb-80cb-1833f5621d90",
   "metadata": {},
   "source": [
    "FINALLY, let's start preparing the contents for the dataframe that we'll later turn into a .txt file for CIGALE to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1295cb23-2ae7-4e83-b321-620a81252bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'redshift', 'hst.wfc.F814W', 'hst.wfc.F814W_err', 'jwst.nircam.F115W', 'jwst.nircam.F115W_err', 'jwst.nircam.F150W', 'jwst.nircam.F150W_err', 'jwst.nircam.F277W', 'jwst.nircam.F277W_err', 'jwst.nircam.F444W', 'jwst.nircam.F444W_err', 'jwst.miri.F770W', 'jwst.miri.F770W_err', 'hst.wfc.F606W', 'hst.wfc.F606W_err', 'jwst.nircam.F090W', 'jwst.nircam.F090W_err', 'jwst.nircam.F200W', 'jwst.nircam.F200W_err', 'jwst.nircam.F356W', 'jwst.nircam.F356W_err', 'jwst.nircam.F410M', 'jwst.nircam.F410M_err']\n"
     ]
    }
   ],
   "source": [
    "### first, we need the column names. \n",
    "# let's make a list for this. we have two known names: id and redshift.\n",
    "column_names = ['id', 'redshift']\n",
    "\n",
    "# next, we retrieve all the SPACE band names and make column names with them\n",
    "for name in space_band_names:\n",
    "    if name == 'f814w' or name == 'f606w': # these are to distinguish the HST bands\n",
    "        column_names.append('hst.wfc.' + name.upper()) # make a column name for the flux\n",
    "        column_names.append('hst.wfc.' + name.upper() + '_err') # make a column name for the error\n",
    "    elif name == 'f770w': # this is to distinguish the MIRI band\n",
    "        column_names.append('jwst.miri.' + name.upper()) # make a column name for the flux\n",
    "        column_names.append('jwst.miri.' + name.upper() + '_err') # make a column name for the error\n",
    "    \n",
    "    else: # the rest are JWST bands\n",
    "        column_names.append('jwst.nircam.' + name.upper()) # make a column name for the flux\n",
    "        column_names.append('jwst.nircam.' + name.upper() + '_err') # make a column name for the error\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d95ed52-3f65-41a0-a6d6-de8c1ebab3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we retrieve all the GROUND band names and make column names with them\n",
    "for name in ground_band_names:\n",
    "    if name.startswith('CFHT'):\n",
    "        column_names.append('cfht.megacam.' + name[5:])\n",
    "        column_names.append('cfht.megacam.' + name[5:] + '_err')\n",
    "    elif name.startswith('HSC') and len(name[7:]) < 2:\n",
    "        column_names.append('subaru.hsc.' + name[4:])\n",
    "        column_names.append('subaru.hsc.' + name[4:] + '_err')\n",
    "    elif name.startswith('UVISTA') and len(name[7:]) < 3:\n",
    "        column_names.append('vista.vircam.' + name[7:])\n",
    "        column_names.append('vista.vircam.' + name[7:] + '_err')\n",
    "    elif name.startswith('SC-IB') or name.startswith('SC-NB'):\n",
    "        column_names.append('subaru.suprime.' + name[3:])\n",
    "        column_names.append('subaru.suprime.' + name[3:] + '_err')\n",
    "    elif name.startswith('IRAC'):\n",
    "        column_names.append('spitzer.irac.' + name[5:])\n",
    "        column_names.append('spitzer.irac.' + name[5:] + '_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19489d67-59c3-4763-a561-76806e2fde22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'redshift', 'hst.wfc.F814W', 'hst.wfc.F814W_err', 'jwst.nircam.F115W', 'jwst.nircam.F115W_err', 'jwst.nircam.F150W', 'jwst.nircam.F150W_err', 'jwst.nircam.F277W', 'jwst.nircam.F277W_err', 'jwst.nircam.F444W', 'jwst.nircam.F444W_err', 'jwst.miri.F770W', 'jwst.miri.F770W_err', 'hst.wfc.F606W', 'hst.wfc.F606W_err', 'jwst.nircam.F090W', 'jwst.nircam.F090W_err', 'jwst.nircam.F200W', 'jwst.nircam.F200W_err', 'jwst.nircam.F356W', 'jwst.nircam.F356W_err', 'jwst.nircam.F410M', 'jwst.nircam.F410M_err', 'cfht.megacam.u', 'cfht.megacam.u_err', 'subaru.hsc.g', 'subaru.hsc.g_err', 'subaru.hsc.r', 'subaru.hsc.r_err', 'subaru.hsc.i', 'subaru.hsc.i_err', 'subaru.hsc.z', 'subaru.hsc.z_err', 'subaru.hsc.y', 'subaru.hsc.y_err', 'vista.vircam.Y', 'vista.vircam.Y_err', 'vista.vircam.J', 'vista.vircam.J_err', 'vista.vircam.H', 'vista.vircam.H_err', 'vista.vircam.Ks', 'vista.vircam.Ks_err', 'subaru.suprime.IB427', 'subaru.suprime.IB427_err', 'subaru.suprime.IB505', 'subaru.suprime.IB505_err', 'subaru.suprime.IB574', 'subaru.suprime.IB574_err', 'subaru.suprime.IB709', 'subaru.suprime.IB709_err', 'subaru.suprime.IB827', 'subaru.suprime.IB827_err', 'subaru.suprime.NB711', 'subaru.suprime.NB711_err', 'subaru.suprime.NB816', 'subaru.suprime.NB816_err', 'spitzer.irac.ch1', 'spitzer.irac.ch1_err', 'spitzer.irac.ch2', 'spitzer.irac.ch2_err', 'spitzer.irac.ch3', 'spitzer.irac.ch3_err']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7818c7d-f0fd-4a43-8cc9-ed385e276a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  redshift  hst.wfc.F814W  hst.wfc.F814W_err  jwst.nircam.F115W  \\\n",
      "0     756228     -99.0       0.000068           0.000010           0.000085   \n",
      "1     756257     -99.0       0.000087           0.000009           0.000078   \n",
      "2     756324     -99.0       0.000043           0.000009           0.000000   \n",
      "3     756353     -99.0       0.000242           0.000014           0.000323   \n",
      "4     756380     -99.0       0.000350           0.000024           0.000404   \n",
      "...      ...       ...            ...                ...                ...   \n",
      "1021  824190     -99.0       0.000039           0.000010           0.000000   \n",
      "1022  824219     -99.0       0.000000           0.000028           0.000000   \n",
      "1023  824230     -99.0       0.000010           0.000002           0.000000   \n",
      "1024  824244     -99.0       0.000024           0.000004           0.000000   \n",
      "1025  824265     -99.0       0.000000           0.000028           0.000000   \n",
      "\n",
      "      jwst.nircam.F115W_err  jwst.nircam.F150W  jwst.nircam.F150W_err  \\\n",
      "0                  0.000015           0.000091               0.000013   \n",
      "1                  0.000010           0.000126               0.000008   \n",
      "2                  0.000063           0.000069               0.000012   \n",
      "3                  0.000019           0.000556               0.000017   \n",
      "4                  0.000051           0.000370               0.000039   \n",
      "...                     ...                ...                    ...   \n",
      "1021               0.000063           0.000000               0.000051   \n",
      "1022               0.000063           0.000000               0.000051   \n",
      "1023               0.000063           0.000000               0.000051   \n",
      "1024               0.000063           0.000000               0.000051   \n",
      "1025               0.000063           0.000000               0.000051   \n",
      "\n",
      "      jwst.nircam.F277W  jwst.nircam.F277W_err  ...  subaru.suprime.NB711  \\\n",
      "0              0.000126               0.000004  ...                   0.0   \n",
      "1              0.000130               0.000003  ...                   0.0   \n",
      "2              0.000119               0.000004  ...                   0.0   \n",
      "3              0.000297               0.000005  ...                   0.0   \n",
      "4              0.000418               0.000015  ...                   0.0   \n",
      "...                 ...                    ...  ...                   ...   \n",
      "1021           0.000041               0.000002  ...                   0.0   \n",
      "1022           0.000000               0.000028  ...                 -99.0   \n",
      "1023           0.000000               0.000028  ...                   0.0   \n",
      "1024           0.000017               0.000005  ...                   0.0   \n",
      "1025           0.000013               0.000003  ...                   0.0   \n",
      "\n",
      "      subaru.suprime.NB711_err  subaru.suprime.NB816  \\\n",
      "0                     0.398107                   0.0   \n",
      "1                     0.398107                   0.0   \n",
      "2                     0.398107                   0.0   \n",
      "3                     0.398107                   0.0   \n",
      "4                     0.398107                   0.0   \n",
      "...                        ...                   ...   \n",
      "1021                  0.398107                   0.0   \n",
      "1022                -99.000000                 -99.0   \n",
      "1023                  0.398107                   0.0   \n",
      "1024                  0.398107                   0.0   \n",
      "1025                  0.398107                   0.0   \n",
      "\n",
      "      subaru.suprime.NB816_err  spitzer.irac.ch1  spitzer.irac.ch1_err  \\\n",
      "0                     0.331131               0.0              0.190546   \n",
      "1                     0.331131               0.0              0.190546   \n",
      "2                     0.331131               0.0              0.190546   \n",
      "3                     0.331131               0.0              0.190546   \n",
      "4                     0.331131               0.0              0.190546   \n",
      "...                        ...               ...                   ...   \n",
      "1021                  0.331131               0.0              0.190546   \n",
      "1022                -99.000000             -99.0            -99.000000   \n",
      "1023                  0.331131               0.0              0.190546   \n",
      "1024                  0.331131               0.0              0.190546   \n",
      "1025                  0.331131               0.0              0.190546   \n",
      "\n",
      "      spitzer.irac.ch2  spitzer.irac.ch2_err  spitzer.irac.ch3  \\\n",
      "0                  0.0               0.20893               0.0   \n",
      "1                  0.0               0.20893               0.0   \n",
      "2                  0.0               0.20893               0.0   \n",
      "3                  0.0               0.20893               0.0   \n",
      "4                  0.0               0.20893               0.0   \n",
      "...                ...                   ...               ...   \n",
      "1021               0.0               0.20893               0.0   \n",
      "1022             -99.0             -99.00000             -99.0   \n",
      "1023               0.0               0.20893               0.0   \n",
      "1024               0.0               0.20893               0.0   \n",
      "1025               0.0               0.20893               0.0   \n",
      "\n",
      "      spitzer.irac.ch3_err  \n",
      "0                 3.311311  \n",
      "1                 3.311311  \n",
      "2                 3.311311  \n",
      "3                 3.311311  \n",
      "4                 3.311311  \n",
      "...                    ...  \n",
      "1021              3.311311  \n",
      "1022            -99.000000  \n",
      "1023              3.311311  \n",
      "1024              3.311311  \n",
      "1025              3.311311  \n",
      "\n",
      "[1026 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "### finally, let's put everything into each of the columns! \n",
    "# to do this, we'll first create a dictionary.\n",
    "mega_dict = {}\n",
    "\n",
    "# next, we'll create an array of redshifts that are all set at -99.0.\n",
    "# these are meant to be placeholders to CIGALE to fill in when it runs.\n",
    "z_arr = np.full(np.size(fluxes[0]), -99.0)\n",
    "\n",
    "# now we start populating the dictionary\n",
    "for idx in range(len(column_names)-1):\n",
    "    # FIRST, we add the id array, as defined above\n",
    "    if idx == 0:\n",
    "        mega_dict[column_names[idx]] = df['id']\n",
    "    # NEXT, we add the redshift array, where all the values are set to -99.0\n",
    "    elif idx == 1:\n",
    "        mega_dict[column_names[idx]] = z_arr\n",
    "    # FINALLY, we start adding the fluxes and errors, based on the band names. we know\n",
    "    # the order of the band names in the band_names list and the column_names list are\n",
    "    # the same, so one by one, we'll populate the next columns.\n",
    "    else:\n",
    "        if idx % 2 == 0:\n",
    "            mega_dict[column_names[idx]] = fluxes[int(idx/2-1)]\n",
    "            mega_dict[column_names[idx+1]] = errors[int(idx/2-1)]\n",
    "\n",
    "cigale_df = pd.DataFrame(mega_dict)\n",
    "print(cigale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec140a4b-5285-4b0e-ba32-a5a55c871a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after some checking, we know there's duplicates in the data table.\n",
    "# this gets rid of the duplicates and keeps only one galaxy instead of one with many duplicates.\n",
    "cigale_df_to_save = cigale_df[cigale_df.duplicated(keep='first')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e21d1a-8cf5-4874-8a8e-ead26daf644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a big .txt file for CIGALE to run\n",
    "cigale_df_to_save.to_csv('cigale_data.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c00e7d0-c88f-441f-a0e2-94f98f46efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a big .csv file for later analysis\n",
    "cigale_df_to_save.to_csv('post_correction_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d3aed-81b9-425b-9395-4de126b11499",
   "metadata": {},
   "source": [
    "ELIMINATE AFTER VISUAL INSPECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbe4f6d3-0df2-425a-a860-d9b9bd408f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nebular_rerun = np.array([659622, 756994, 661909, 642604, 614224, 614320, 614548, 614670, \n",
    "                 659534, 661661, 661662, 661988, 661989, 662092, 756380, 756650, \n",
    "                 757025, 759202, 781608, 781845, 784642, 784663, 823371, 759485, \n",
    "                 759140, 759207, 829990, 780261, 757435, 757212, 659693, 614256, \n",
    "                 641835, 641328, 614660, 614700], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec009060-5352-4aae-a806-14f425249ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "postage_check = np.array([614453, 660158, 661580, 661675, 661906, 780995, 759290, 824112,\n",
    "                         781056, 642340, 642380, 614114], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ff383a4-6de6-4662-9d8d-01c9dcfe79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage = np.array([614134, 614257, 641889, 642233, 642502, 642581, 642605,\n",
    "                    659467, 661883, 661884, 683294, 683364, 684046, 684102, 756594, \n",
    "                    757210, 782194, 782746, 783117, 783144, 783257, 784766, 823655, 823981, 830151, 680965], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e98f9934-4813-4f14-9fee-f1c45fe1f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes out the rows that are in nebular_rerun\n",
    "nebular = cigale_df_to_save.loc[cigale_df_to_save['id'].isin(nebular_rerun)]\n",
    "nebular.to_csv('nebular_rerun_data.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4ef065-ddce-40e8-a82d-8172899bbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes out the rows that are in postage_check\n",
    "postage = cigale_df_to_save.loc[cigale_df_to_save['id'].isin(postage_check)]\n",
    "postage.to_csv('postage_check_data.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2ad38e8-75bd-418d-af29-bbc8ca6cd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_fits = np.array([756228, 756324, 756381, 756542, 756650, 756791, 756809, 756895,\n",
    "       756931, 780235, 780261, 780365, 780483, 780489, 780511, 780592,\n",
    "       780808, 780830, 780870, 780882, 780995, 781053, 781056, 757782,\n",
    "       757931, 757934, 757952, 757967, 758035, 758076, 758096, 758165,\n",
    "       782619, 782740, 782969, 783186, 783189, 783202, 783240, 804680,\n",
    "       804711, 830212, 830422, 830622, 756960, 756994, 757025, 757035,\n",
    "       757177, 757208, 757258, 757350, 757396, 757532, 780960, 781069,\n",
    "       781337, 781608, 781836, 781863, 758845, 758998, 759022, 759045,\n",
    "       759140, 759202, 759207, 759298, 759334, 759455, 759460, 759545,\n",
    "       759592, 759715, 783764, 783888, 783941, 783964, 784079, 784159,\n",
    "       784266, 784406, 784483, 784557, 784569, 784580, 784614, 784646,\n",
    "       784663, 614117, 614284, 614318, 614521, 614660, 641810, 642465,\n",
    "       642503, 614192, 661790, 661825, 661910, 662039, 662092, 683386,\n",
    "       659472, 659600, 659694, 659753, 659914, 680426, 680812, 757887,\n",
    "       758032, 758360, 782329, 782581, 782661, 782821, 782838, 782882,\n",
    "       782883, 783197, 783322, 776150, 799188, 799221, 799317, 799360,\n",
    "       799493, 799560, 799665, 799673, 799674, 799686, 799885, 799944,\n",
    "       799949, 799972, 823354, 823362, 823447, 823454, 823493, 823557,\n",
    "       823690, 823724, 823796, 823832, 823841, 823918, 823998, 824034,\n",
    "       824065, 824112, 824190], dtype='object')\n",
    "# this takes out the rows that are in nebular_rerun\n",
    "good_fits_only = cigale_df_to_save.loc[cigale_df_to_save['id'].isin(good_fits)]\n",
    "good_fits_only.to_csv('tentative_data.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
