{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511616df-454a-4743-b69b-93ccccfede49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets up basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "import astropy.cosmology.units as cu\n",
    "\n",
    "# this sets up matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this sets up astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import pixel_to_skycoord, skycoord_to_pixel\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.coordinates import SkyCoord, Angle, match_coordinates_sky, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e13460-b56d-49ee-8b63-4a2829e22503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reads in the new neighbor catalog, originally made for CIGALE\n",
    "df = pd.read_csv('post_correction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9520e728-c08d-48d7-93a1-d32cd224b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before all the eliminations, there are a total of 994 sources.\n"
     ]
    }
   ],
   "source": [
    "print('Before all the eliminations, there are a total of', df.shape[0], 'sources.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0fae3-4633-4751-82d5-6c0a6bfb534d",
   "metadata": {},
   "source": [
    "# <b>CRITERION 1</b>: Minimum of 3 detections, or less if there's A3COSMOS/ALMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104839bf-2c11-4a59-a580-b1c736306ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a previous .csv file, all the neighbors are id'd based on their central galaxy.\n",
    "# since this id is such a minor part of our work and isn't present in our later .csv or .txt files,\n",
    "# we just retrieve these \"our_id\" values from the old .csv file, and then use them for our new work.\n",
    "df2 = pd.read_csv('neighbor_data.csv')\n",
    "catalog_id = df2[df2['id'].duplicated(keep='first')==False]['id']\n",
    "our_id = df2[df2['id'].duplicated(keep='first')==False]['our_id']\n",
    "our_ra = df2[df2['id'].duplicated(keep='first')==False]['ra']\n",
    "our_dec = df2[df2['id'].duplicated(keep='first')==False]['dec']\n",
    "our_z = df2[df2['id'].duplicated(keep='first')==False]['z_spec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf390be-873f-48c4-9ca9-8db191b2fca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this opens the HDU list of the .fits catalog from A3COSMOS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hdu_list \u001b[38;5;241m=\u001b[39m fits\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m hdu_list\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# this gets the data of the catalog\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:222\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HDUList\u001b[38;5;241m.\u001b[39mfromfile(\n\u001b[1;32m    223\u001b[0m     name,\n\u001b[1;32m    224\u001b[0m     mode,\n\u001b[1;32m    225\u001b[0m     memmap,\n\u001b[1;32m    226\u001b[0m     save_backup,\n\u001b[1;32m    227\u001b[0m     cache,\n\u001b[1;32m    228\u001b[0m     lazy_load_hdus,\n\u001b[1;32m    229\u001b[0m     ignore_missing_simple,\n\u001b[1;32m    230\u001b[0m     use_fsspec\u001b[38;5;241m=\u001b[39muse_fsspec,\n\u001b[1;32m    231\u001b[0m     fsspec_kwargs\u001b[38;5;241m=\u001b[39mfsspec_kwargs,\n\u001b[1;32m    232\u001b[0m     decompress_in_memory\u001b[38;5;241m=\u001b[39mdecompress_in_memory,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    234\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:486\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    478\u001b[0m ):\n\u001b[1;32m    479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_readfrom(\n\u001b[1;32m    487\u001b[0m         fileobj\u001b[38;5;241m=\u001b[39mfileobj,\n\u001b[1;32m    488\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    489\u001b[0m         memmap\u001b[38;5;241m=\u001b[39mmemmap,\n\u001b[1;32m    490\u001b[0m         save_backup\u001b[38;5;241m=\u001b[39msave_backup,\n\u001b[1;32m    491\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    492\u001b[0m         ignore_missing_simple\u001b[38;5;241m=\u001b[39mignore_missing_simple,\n\u001b[1;32m    493\u001b[0m         lazy_load_hdus\u001b[38;5;241m=\u001b[39mlazy_load_hdus,\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    495\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:1168\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m _File(\n\u001b[1;32m   1169\u001b[0m             fileobj,\n\u001b[1;32m   1170\u001b[0m             mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1171\u001b[0m             memmap\u001b[38;5;241m=\u001b[39mmemmap,\n\u001b[1;32m   1172\u001b[0m             cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1173\u001b[0m             use_fsspec\u001b[38;5;241m=\u001b[39muse_fsspec,\n\u001b[1;32m   1174\u001b[0m             fsspec_kwargs\u001b[38;5;241m=\u001b[39mfsspec_kwargs,\n\u001b[1;32m   1175\u001b[0m             decompress_in_memory\u001b[38;5;241m=\u001b[39mdecompress_in_memory,\n\u001b[1;32m   1176\u001b[0m         )\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/astropy/io/fits/file.py:218\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs, decompress_in_memory)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filename(fileobj, mode, overwrite)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/astropy/io/fits/file.py:651\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    648\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, IO_FITS_MODES[mode])\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits'"
     ]
    }
   ],
   "source": [
    "# this opens the HDU list of the .fits catalog from A3COSMOS\n",
    "hdu_list = fits.open('/Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits')\n",
    "hdu_list.info()\n",
    "\n",
    "# this gets the data of the catalog\n",
    "a3cosmos = hdu_list[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb14330-b418-47dc-a1ed-2796c86bc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### matching coords from the A3COSMOS catalog using SkyCoord \n",
    "# create SkyCoord arrays (?) with the RA and Dec of the galaxies in both catalogs\n",
    "radio_cat = SkyCoord(ra=a3cosmos['RAJ2000']*u.degree, dec=a3cosmos['DEJ2000']*u.degree)\n",
    "spec_cat = SkyCoord(ra=our_ra.values*u.degree, dec=our_dec.values*u.degree)\n",
    "\n",
    "# use search_around_sky to find matching indices (matching in RA and Dec) in each catalog\n",
    "idx_radio, idx_spec, d2d, d3d = spec_cat.search_around_sky(radio_cat, 1*u.arcsec)\n",
    "\n",
    "# use the matching indices to the new catalog to see where we have ground-based data of our neighbors\n",
    "print(np.size(idx_radio), 'is the number of matches between the A3COSMOS and the spectroscopic catalogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac828be5-9d63-4467-b1c2-68a99bd3e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this calls the names of all the columns with flux measurements for all the galaxies\n",
    "f_cols = [col for col in df.columns if '_err' not in col and col != 'id' and col != 'redshift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82af9b3-8c48-4148-8f90-c0e132d92cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves all the neighbor ids that pass criterion 1\n",
    "crit1_neigh_id = []\n",
    "\n",
    "# this loops over all the galaxies from the .csv file, then reads their corresponding fluxes\n",
    "# in all our bands to see if each of them has at least 3 different detections. if said galaxy does, \n",
    "# then we save the id of that galaxy, meaning that it passes criterion 1.\n",
    "\n",
    "# this loops over each of the 9 QGs in our sample group\n",
    "for id in catalog_id.values:\n",
    "    \n",
    "    # this retrieves all the corresponding fluxes of the galaxy with the id called\n",
    "    all_bands = df[df['id'] == id][f_cols].values\n",
    "\n",
    "    # this counts how many of these fluxes are non-zeros (i.e. how many detections there are)\n",
    "    available_fluxes = np.count_nonzero(all_bands)\n",
    "\n",
    "    # this adds the galaxy's id into crit1_neigh_id if the galaxy has more than 3 detections\n",
    "    if available_fluxes >= 3:\n",
    "        crit1_neigh_id.append(id)\n",
    "        \n",
    "print(len(crit1_neigh_id), 'is the total amount of neighbors that pass criterion 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d2227-6910-4180-85d9-25ca7a1ea5af",
   "metadata": {},
   "source": [
    "# <b>CRITERION 2:</b> |z$_{QG}$ - z$_{gal}$| < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9c5d16-3ce7-4713-88e0-a88699e19d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: out/results.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU    386   994R x 127C   [K, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "# this reads in the results FITS file that CIGALE made\n",
    "cigale_results = fits.open('out/results.fits')\n",
    "cigale_results.info()\n",
    "\n",
    "# this saves the WCS setting to be used later, just in case\n",
    "cigale_wcs = WCS(cigale_results[1].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae8ead10-8c7c-4fbf-b78d-bb1b77a9ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the data from the results FITS file\n",
    "cigale_data = Table(cigale_results[1].data).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "883b0a51-87b1-4dbf-a3df-299a4c82e2f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crit1_neigh_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this selects only the rows in cigale_data and our_id\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# whose corresponding source already passed criterion 1\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m reduced_cigale \u001b[38;5;241m=\u001b[39m cigale_data\u001b[38;5;241m.\u001b[39mloc[cigale_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(crit1_neigh_id)]\n\u001b[1;32m      4\u001b[0m reduced_our_id \u001b[38;5;241m=\u001b[39m our_id[catalog_id\u001b[38;5;241m.\u001b[39misin(crit1_neigh_id)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crit1_neigh_id' is not defined"
     ]
    }
   ],
   "source": [
    "# this selects only the rows in cigale_data and our_id\n",
    "# whose corresponding source already passed criterion 1\n",
    "reduced_cigale = cigale_data.loc[cigale_data['id'].isin(crit1_neigh_id)]\n",
    "reduced_our_id = our_id[catalog_id.isin(crit1_neigh_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17ec0d-e2aa-4f02-8c2b-85739575b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigale_id = reduced_cigale['id'].values\n",
    "cigale_z = reduced_cigale['bayes.universe.redshift'].values\n",
    "cigale_z_err = reduced_cigale['bayes.universe.redshift_err'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8af90-3cbb-493a-8955-820615d3fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read in the RAs and Decs of our 9 galaxies\n",
    "info = np.genfromtxt('basic_data.txt', delimiter=' ', dtype=['U15', '<f8','<f8', '<f8'])\n",
    "\n",
    "# this gets the galaxy redshifts for all the 9 galaxies\n",
    "galaxy_redshift = np.zeros(np.size(info), dtype=float)\n",
    "for i in range(np.size(info)):\n",
    "    galaxy_redshift[i] = info[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b292ea-23a0-4abe-8b77-050e65f4f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves all the neighbor ids that pass criterion 2\n",
    "crit2_neigh_id = []\n",
    "\n",
    "# this loops over each of the 9 QGs in our sample group\n",
    "for our_galaxy in range(np.size(galaxy_redshift)):\n",
    "    \n",
    "    # this selects the neighbor IDs, ONLY the ones that passed criterion 1\n",
    "    neigh_id = np.array(cigale_id[reduced_our_id==our_galaxy])\n",
    "\n",
    "    # this reads in the estimated z and errors of all the neighbors around each galaxy that passed criterion 1\n",
    "    neigh_z = np.array(cigale_z[reduced_our_id==our_galaxy])\n",
    "    neigh_z_err = np.array(cigale_z_err[reduced_our_id==our_galaxy])\n",
    "\n",
    "    # this sets criterion 2\n",
    "    criteria = (np.abs(neigh_z + neigh_z_err - galaxy_redshift[our_galaxy]) <= 0.5) | (np.abs(neigh_z - neigh_z_err - galaxy_redshift[our_galaxy]) <= 0.5)\n",
    "\n",
    "    # this finds neighbor IDs that pass criterion 2\n",
    "    ok_neigh_id = neigh_id[criteria]\n",
    "\n",
    "    # this saves the indices of the neighbors that pass criterion 2\n",
    "    crit2_neigh_id.extend(ok_neigh_id)\n",
    "\n",
    "print(len(crit2_neigh_id), 'is the total amount of neighbors that pass criterion 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8adaa-1091-4070-a50e-d9e8448b1f60",
   "metadata": {},
   "source": [
    "# RECHECKS! \n",
    "## Not all of the 181 neighbors produce either good or bad fits. Now we write code to do the reruns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef0f602-77bb-4904-84e7-59ac5cddde07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "nebular_rerun = np.array([659622, 756994, 661909, 642604, 614224, 614320, 614548, 614670, \n",
    "                 659534, 661661, 661662, 661988, 661989, 662092, 756380, 756650, \n",
    "                 757025, 759202, 781608, 781845, 784642, 784663, 823371, 759485, \n",
    "                 759140, 759207, 829990, 780261, 757435, 757212, 659693, 614256, \n",
    "                 641835, 641328, 614660, 614700], dtype='object')\n",
    "print(np.size(nebular_rerun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a995eff-3313-4e2c-aedf-7c9210b5373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage = np.array("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
