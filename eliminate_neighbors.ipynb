{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511616df-454a-4743-b69b-93ccccfede49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets up basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "import astropy.cosmology.units as cu\n",
    "\n",
    "# this sets up matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this sets up astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import pixel_to_skycoord, skycoord_to_pixel\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.coordinates import SkyCoord, Angle, match_coordinates_sky, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e13460-b56d-49ee-8b63-4a2829e22503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reads in the new neighbor catalog, originally made for CIGALE\n",
    "df = pd.read_csv('post_correction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9520e728-c08d-48d7-93a1-d32cd224b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before all the eliminations, there are a total of 994 sources.\n"
     ]
    }
   ],
   "source": [
    "print('Before all the eliminations, there are a total of', df.shape[0], 'sources.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0fae3-4633-4751-82d5-6c0a6bfb534d",
   "metadata": {},
   "source": [
    "# <b>CRITERION 1</b>: Minimum of 3 detections, or less if there's A3COSMOS/ALMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104839bf-2c11-4a59-a580-b1c736306ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a previous .csv file, all the neighbors are id'd based on their central galaxy.\n",
    "# since this id is such a minor part of our work and isn't present in our later .csv or .txt files,\n",
    "# we just retrieve these \"our_id\" values from the old .csv file, and then use them for our new work.\n",
    "df2 = pd.read_csv('neighbor_data.csv')\n",
    "df2 = df2[df2['id'].duplicated(keep='first')==False]\n",
    "catalog_id = df2['id']\n",
    "our_id = df2['our_id']\n",
    "our_ra = df2['ra']\n",
    "our_dec = df2['dec']\n",
    "our_z = df2['z_spec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf390be-873f-48c4-9ca9-8db191b2fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      45   ()      \n",
      "  1  J_ApJS_244_40_blind    1 BinTableHDU    115   1134R x 16C   [D, D, D, D, E, E, E, E, E, E, E, D, E, E, E, B]   \n"
     ]
    }
   ],
   "source": [
    "# this opens the HDU list of the .fits catalog from A3COSMOS\n",
    "hdu_list = fits.open('/Volumes/LaCie/COSMOS_DATA/a3cosmos_blind.fits')\n",
    "hdu_list.info()\n",
    "\n",
    "# this gets the data of the catalog\n",
    "a3cosmos = hdu_list[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb14330-b418-47dc-a1ed-2796c86bc4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is the number of matches between the A3COSMOS and the spectroscopic catalogs.\n"
     ]
    }
   ],
   "source": [
    "### matching coords from the A3COSMOS catalog using SkyCoord \n",
    "# create SkyCoord arrays (?) with the RA and Dec of the galaxies in both catalogs\n",
    "radio_cat = SkyCoord(ra=a3cosmos['RAJ2000']*u.degree, dec=a3cosmos['DEJ2000']*u.degree)\n",
    "spec_cat = SkyCoord(ra=our_ra.values*u.degree, dec=our_dec.values*u.degree)\n",
    "\n",
    "# use search_around_sky to find matching indices (matching in RA and Dec) in each catalog\n",
    "idx_radio, idx_spec, d2d, d3d = spec_cat.search_around_sky(radio_cat, 1*u.arcsec)\n",
    "\n",
    "# use the matching indices to the new catalog to see where we have ground-based data of our neighbors\n",
    "print(np.size(idx_radio), 'is the number of matches between the A3COSMOS and the spectroscopic catalogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac828be5-9d63-4467-b1c2-68a99bd3e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this calls the names of all the columns with flux measurements for all the galaxies\n",
    "f_cols = [col for col in df.columns if '_err' not in col and col != 'id' and col != 'redshift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82af9b3-8c48-4148-8f90-c0e132d92cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849 is the total amount of neighbors that pass criterion 1.\n"
     ]
    }
   ],
   "source": [
    "# this saves all the neighbor ids that pass criterion 1\n",
    "crit1_neigh_id = []\n",
    "\n",
    "# this loops over all the galaxies from the .csv file, then reads their corresponding fluxes\n",
    "# in all our bands to see if each of them has at least 3 different detections. if said galaxy does, \n",
    "# then we save the id of that galaxy, meaning that it passes criterion 1.\n",
    "\n",
    "# this loops over each of the 9 QGs in our sample group\n",
    "for id in catalog_id.values:\n",
    "    \n",
    "    # this retrieves all the corresponding fluxes of the galaxy with the id called\n",
    "    all_bands = df[df['id'] == id][f_cols].values\n",
    "\n",
    "    # this counts how many of these fluxes are non-zeros (i.e. how many detections there are)\n",
    "    available_fluxes = np.count_nonzero(all_bands)\n",
    "\n",
    "    # this adds the galaxy's id into crit1_neigh_id if the galaxy has more than 3 detections\n",
    "    if available_fluxes >= 3:\n",
    "        crit1_neigh_id.append(id)\n",
    "        \n",
    "print(len(crit1_neigh_id), 'is the total amount of neighbors that pass criterion 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d2227-6910-4180-85d9-25ca7a1ea5af",
   "metadata": {},
   "source": [
    "# <b>CRITERION 2:</b> |z$_{QG}$ - z$_{gal}$| < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9c5d16-3ce7-4713-88e0-a88699e19d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: out_all/results.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU    386   994R x 127C   [K, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "# this reads in the results FITS file that CIGALE made\n",
    "cigale_results = fits.open('out_all/results.fits')\n",
    "cigale_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8ead10-8c7c-4fbf-b78d-bb1b77a9ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the data from the results FITS file\n",
    "cigale_data = Table(cigale_results[1].data).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883b0a51-87b1-4dbf-a3df-299a4c82e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this selects only the rows in cigale_data and our_id\n",
    "# whose corresponding source already passed criterion 1\n",
    "reduced_cigale = cigale_data.loc[cigale_data['id'].isin(crit1_neigh_id)]\n",
    "reduced_our_id = our_id[catalog_id.isin(crit1_neigh_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a17ec0d-e2aa-4f02-8c2b-85739575b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigale_id = reduced_cigale['id'].values\n",
    "cigale_z = reduced_cigale['bayes.universe.redshift'].values\n",
    "cigale_z_err = reduced_cigale['bayes.universe.redshift_err'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bc8af90-3cbb-493a-8955-820615d3fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read in the RAs and Decs of our 9 galaxies\n",
    "info = np.genfromtxt('basic_data.txt', delimiter=' ', dtype=['U15', '<f8','<f8', '<f8'])\n",
    "\n",
    "# this gets the galaxy redshifts for all the 9 galaxies\n",
    "galaxy_redshift = np.zeros(np.size(info), dtype=float)\n",
    "for i in range(np.size(info)):\n",
    "    galaxy_redshift[i] = info[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b292ea-23a0-4abe-8b77-050e65f4f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 is the total amount of neighbors that pass criterion 2.\n"
     ]
    }
   ],
   "source": [
    "# this saves all the neighbor ids that pass criterion 2\n",
    "crit2_neigh_id = []\n",
    "\n",
    "# this loops over each of the 9 QGs in our sample group\n",
    "for our_galaxy in range(np.size(galaxy_redshift)):\n",
    "    # this selects the neighbor IDs, ONLY the ones that passed criterion 1\n",
    "    neigh_id = np.array(cigale_id[reduced_our_id==our_galaxy])\n",
    "\n",
    "    # this reads in the estimated z and errors of all the neighbors around each galaxy that passed criterion 1\n",
    "    neigh_z = np.array(cigale_z[reduced_our_id==our_galaxy])\n",
    "    neigh_z_err = np.array(cigale_z_err[reduced_our_id==our_galaxy])\n",
    "\n",
    "    # this sets criterion 2\n",
    "    criteria = (np.abs(neigh_z + neigh_z_err - galaxy_redshift[our_galaxy]) <= 0.5) | (np.abs(neigh_z - neigh_z_err - galaxy_redshift[our_galaxy]) <= 0.5)\n",
    "\n",
    "    # this finds neighbor IDs that pass criterion 2\n",
    "    ok_neigh_id = neigh_id[criteria]\n",
    "\n",
    "    # this saves the indices of the neighbors that pass criterion 2\n",
    "    crit2_neigh_id.extend(ok_neigh_id)\n",
    "\n",
    "print(len(crit2_neigh_id), 'is the total amount of neighbors that pass criterion 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8adaa-1091-4070-a50e-d9e8448b1f60",
   "metadata": {},
   "source": [
    "# <b>Penultimate Elimination</b>\n",
    "\n",
    "After visually inspecting all the 181 fits, we separate them into good fits, fits that need to be rerun without nebular emissions, fits that need to be checked by looking at the postage stamp (and later rerunning without nebular emissions), and completely bad fits. Below are the IDs that belong to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef0f602-77bb-4904-84e7-59ac5cddde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nebular_rerun = np.array([659622, 756994, 661909, 642604, 614224, 614320, 614548, 614670, \n",
    "                 659534, 661661, 661662, 661988, 661989, 662092, 756380, 756650, \n",
    "                 757025, 759202, 781608, 781845, 784642, 784663, 823371, 759485, \n",
    "                 759140, 759207, 829990, 780261, 757435, 757212, 659693, 614256, \n",
    "                 641835, 641328, 614660, 614700], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a995eff-3313-4e2c-aedf-7c9210b5373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "postage_check = np.array([614453, 660158, 661580, 661675, 661906, 780995, 759290, 824112,\n",
    "                         781056, 642340, 642380, 614114], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23bff759-c2b6-431a-acba-9aa39326e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage = np.array([614134, 614257, 641889, 642233, 642502, 642581, 642605,\n",
    "                    659467, 661883, 661884, 683294, 683364, 684046, 684102, 756594, \n",
    "                    757210, 782194, 782746, 783117, 783144, 783257, 784766, 823655, 823981, 830151, 680965], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f67dec-0263-4d4a-8206-b733e85d1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_fits_nebular = np.setdiff1d(crit2_neigh_id, np.concatenate((nebular_rerun, postage_check, garbage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50794a3-ea09-4620-ac44-ca6cd1071a8f",
   "metadata": {},
   "source": [
    "# <b>Final Elimination</b>\n",
    "\n",
    "After rerunning both the nebular and postage categories, we select the fits that should be selected without nebular emissions. We also decide which fits with nebular emissions should be kept. Their IDs are entered manually downhere, then combined with the good_fits array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb8a5aaf-4713-4467-b21f-e7ce7fdc8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_no_nebular = np.array([614224, 614660, 614670, 614700, 659622, 661909, 662092, 756650, 756994, \n",
    "                            757025, 757212, 757435, 659693, 661989, 759140, 759202, \n",
    "                            784663, 824112, 780995], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0de50eb3-c41e-4278-a912-6f6f59f9c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_nebular = np.array([756380, 781608, 780261, 823371, 829990, 614114, 781056], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6d532e-5cf0-4cc0-83f7-2fa4c6cc29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_fits_nebular = np.concatenate((good_fits_nebular, keep_nebular))\n",
    "good_fits_no_nebular = keep_no_nebular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e27a3473-6c7a-4db1-a1cc-d6c072aa2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: out_no_nebular/results.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU    368   36R x 121C   [K, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "# this reads in the FIRST results.fits file that CIGALE made without nebular emissions\n",
    "cigale_noneb1 = fits.open('out_no_nebular/results.fits')\n",
    "cigale_noneb1.info()\n",
    "\n",
    "# this gets the data from the FIRST results.fits file\n",
    "cigale_data_noneb1 = Table(cigale_noneb1[1].data).to_pandas()\n",
    "\n",
    "# this takes the CIGALE-generated info\n",
    "info_good_fits_noneb1 = cigale_data_noneb1.loc[cigale_data_noneb1['id'].isin(good_fits_no_nebular)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15125d5a-102d-4735-8abd-cba1e52878f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: out_postage_recheck/results.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU    368   12R x 121C   [K, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, D]   \n"
     ]
    }
   ],
   "source": [
    "# this reads in the SECOND results.fits file that CIGALE made without nebular emissions\n",
    "cigale_noneb2 = fits.open('out_postage_recheck/results.fits')\n",
    "cigale_noneb2.info()\n",
    "\n",
    "# this gets the data from the SECOND results.fits file\n",
    "cigale_data_noneb2 = Table(cigale_noneb2[1].data).to_pandas()\n",
    "\n",
    "# this takes the CIGALE-generated info\n",
    "info_good_fits_noneb2 = cigale_data_noneb2.loc[cigale_data_noneb2['id'].isin(good_fits_no_nebular)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e7549e6-8e25-4839-8b00-e6791b610925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, make one mega DataFrame with all the good no-nebular fits\n",
    "info_good_fits_noneb = pd.concat([info_good_fits_noneb1, info_good_fits_noneb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c6a773b-7d1b-4522-967a-1a85ccb9683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, make one mega DataFrame with all the good with-nebular fits\n",
    "info_good_fits_nebular = cigale_data.loc[cigale_data['id'].isin(good_fits_nebular)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02375610-e603-4e18-b913-cb907f9c5785",
   "metadata": {},
   "source": [
    "# <b>Final DataFrame</b>\n",
    "\n",
    "Now, we make one FINAL DataFrame with all our potential neighbors. We also retrieve their RA and Dec from the original <b>neighbor_data.csv</b> file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0e5bd4a-fb98-40c0-8f12-64911fbb8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_good_fits = pd.concat([info_good_fits_noneb, info_good_fits_nebular])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6d1b2d6-5fa8-43ff-818a-2b0bb8827f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lines retrieve their RA and Dec from the original neighbor_data.csv file\n",
    "good_fits_ra = df2[['id', 'ra']].loc[catalog_id.isin(info_good_fits['id'].values)]\n",
    "good_fits_dec = df2[['id', 'dec']].loc[catalog_id.isin(info_good_fits['id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0445cc1-e6e4-4b89-aeb0-59c56aae8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a DataFrame with the RA and Dec of our good-fits neighbors\n",
    "good_fits_df = pd.merge(pd.merge(info_good_fits, good_fits_ra, on=\"id\", how=\"left\"), good_fits_dec, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a565aea9-3cd6-4c39-956d-8629eb5cf049",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = good_fits_df[['id', 'ra', 'dec', 'bayes.universe.redshift', 'bayes.universe.redshift_err', \n",
    "                         'bayes.stellar.m_star', 'bayes.stellar.m_star_err', 'bayes.sfh.sfr', \n",
    "                         'bayes.sfh.sfr_err', 'bayes.sfh.sfr100Myrs', 'bayes.sfh.sfr100Myrs_err', \n",
    "                         'bayes.attenuation.E_BVs', 'bayes.attenuation.E_BVs_err']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11583e4c-c138-4089-8ee6-bcfb722c504a",
   "metadata": {},
   "source": [
    "## <b>BEHOLD!</b> Our final table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbe7a257-e63a-4fde-9eb1-c6b2f55b3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id          ra       dec  bayes.universe.redshift  \\\n",
      "0    756650  150.059622  2.379230                 4.857374   \n",
      "1    756994  150.065793  2.380723                 4.937202   \n",
      "2    757025  150.066598  2.380856                 4.934577   \n",
      "3    757212  150.066115  2.383224                 2.310612   \n",
      "4    757435  150.069042  2.384513                 1.660271   \n",
      "..      ...         ...       ...                      ...   \n",
      "136  823918  150.112749  2.330474                 4.032831   \n",
      "137  823998  150.106560  2.333423                 4.083596   \n",
      "138  824034  150.108001  2.333181                 2.498904   \n",
      "139  824065  150.112878  2.331558                 2.273188   \n",
      "140  824190  150.108294  2.334233                 4.166410   \n",
      "\n",
      "     bayes.universe.redshift_err  bayes.stellar.m_star  \\\n",
      "0                       0.210896          2.476156e+09   \n",
      "1                       0.129637          1.921869e+09   \n",
      "2                       0.160069          3.589874e+09   \n",
      "3                       1.975078          4.860648e+07   \n",
      "4                       1.714578          4.740173e+07   \n",
      "..                           ...                   ...   \n",
      "136                     1.201176          2.390376e+08   \n",
      "137                     1.173910          1.780884e+08   \n",
      "138                     0.274120          3.332183e+07   \n",
      "139                     1.373480          1.765787e+07   \n",
      "140                     0.535599          1.475570e+08   \n",
      "\n",
      "     bayes.stellar.m_star_err  bayes.sfh.sfr  bayes.sfh.sfr_err  \\\n",
      "0                5.776453e+08       4.082569           6.926329   \n",
      "1                2.773408e+08       5.041217           1.369508   \n",
      "2                4.712428e+08       2.005455           1.520948   \n",
      "3                5.570443e+07       0.701450           0.888249   \n",
      "4                7.491466e+07       0.347077           0.620998   \n",
      "..                        ...            ...                ...   \n",
      "136              1.329441e+08       1.164570           0.704235   \n",
      "137              1.112675e+08       1.449340           0.713589   \n",
      "138              1.174775e+07       0.222789           0.081977   \n",
      "139              1.262856e+07       0.352016           0.271054   \n",
      "140              5.801090e+07       1.160095           0.513051   \n",
      "\n",
      "     bayes.sfh.sfr100Myrs  bayes.sfh.sfr100Myrs_err  bayes.attenuation.E_BVs  \\\n",
      "0                3.818634                  4.494412                 0.041253   \n",
      "1                5.432712                  1.651806                 0.014609   \n",
      "2                2.937276                  1.231834                 0.030491   \n",
      "3                0.477021                  0.564688                 0.009082   \n",
      "4                0.300302                  0.483135                 0.016500   \n",
      "..                    ...                       ...                      ...   \n",
      "136              1.157165                  0.566211                 0.012505   \n",
      "137              1.243425                  0.516095                 0.004613   \n",
      "138              0.210762                  0.049898                 0.007213   \n",
      "139              0.210013                  0.158681                 0.004606   \n",
      "140              0.986643                  0.248689                 0.018393   \n",
      "\n",
      "     bayes.attenuation.E_BVs_err  \n",
      "0                       0.076094  \n",
      "1                       0.026910  \n",
      "2                       0.030979  \n",
      "3                       0.027108  \n",
      "4                       0.035044  \n",
      "..                           ...  \n",
      "136                     0.028165  \n",
      "137                     0.016457  \n",
      "138                     0.019318  \n",
      "139                     0.018501  \n",
      "140                     0.030994  \n",
      "\n",
      "[141 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727205f-914f-4f3c-95fa-a18b36f530a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
